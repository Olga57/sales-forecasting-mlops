# fmcg_forecasting

**Цыбакова Ольга**

_В описании все ссылки привязаны к фразам для того, чтобы документ был
красивее. Если не видно ссылок, в конце этого документа на всякий случай они
все продублированы._


## Постановка задачи

Цель проекта — разработать нейросетевую модель, которая будет прогнозировать месячный объём продаж (MT_Volume) определённой продуктовой категории (например, BAGS) в канале продаж Discounters на основе исторических данных и маркетинговых KPI.

Прогнозирование необходимо компании для:
корректного планирования производства, закупок и логистики,


бюджетирования трейд-маркетинговой активности,


оценки влияния цены, дистрибуции (Universe), Penetration, Frequency и других факторов на продажи,


более точного формирования плана продаж по категориям продуктов.
Проект использует данные формата FMCG-категорий, где продажи зависят от поведения покупателей и рыночных условий.
В рамках проекта будет построена модель, способная учитывать мультифакторную структуру/

### Формат входных и выходных данных


Модель принимает на вход таблицу, где каждая строка соответствует одному месяцу по определённой категории и каналу продаж.

После предварительной обработки данные преобразуются в тензоры формата:

\[
X \in \mathbb{R}^{T \times d}
\]

- **T** — длина временного окна (например, 24–36 месяцев).
- **d** — количество признаков (8–15, в зависимости от используемых KPI).

Все признаки проходят нормализацию (например, `StandardScaler` или `MinMaxScaler`). Категориальные признаки кодируются с помощью one-hot кодирования или преобразуются в циклические признаки (например, месяц → sin/cos).

Примеры признаков:

- `MT_Volume` — целевой показатель на предыдущих шагах (target lag).
- `NT_Price per …` — средняя цена по каналу/категории.
- `NT_Avg Line` — среднее количество товарных позиций.
- `NT_Universe`, `MT_Universe` — размеры охвата рынка.
- `Frequency`, `Penetration` — метрики вовлечённости и охвата.
- `Spend per Trip`, `Volume per Trip` — затраты и объём на покупку/транзакцию.

### Выходные данные

Модель прогнозирует объём продаж на заданный горизонт:

\[
\hat{y} \in \mathbb{R}^{H}
\]

- **H** — горизонт прогноза (например, 1 месяц, 3 месяца или 6 месяцев).
- Формат выхода: тензор размерности `(batch_size, H)`.

Таким образом, для каждого батча входных данных модель возвращает прогнозы объёма продаж на заданный период.


### Метрики


Для оценки качества прогнозов используются следующие метрики:

- **MAE (Mean Absolute Error)**
  Хорошо показывает точные отклонения по объёму.

- **RMSE (Root Mean Squared Error)**
  Жёстче штрафует крупные ошибки, полезно при всплесках.

- **MAPE / sMAPE (Mean / Symmetric Absolute Percentage Error)**
  Используются аккуратно: MAPE плохо работает при низких объёмах, поэтому предпочтительнее sMAPE.

- **WAPE (Weighted Absolute Percentage Error)**
  Стандартная метрика в прогнозировании спроса в индустрии.

**Предполагаемые значения метрик:**

- WAPE: 10–20% при хорошей модели
- MAE: снижение минимум на 15–25% относительно бейзлайна
- RMSE: стабильно ниже, чем у моделей сезонной наивной прогнозности

---

## Валидация и тест

Так как данные временные, для разделения выборок используется `TimeSeriesSplit` (rolling window или expanding window).

**Пример разбиения данных:**

- Train: 2018–2022
- Validation: 2023
- Test: 2024

**Обеспечение воспроизводимости:**

- Фиксирование seed: `torch.manual_seed(42)`
- Использование конкретных дат разбиения
- Закрытие утечек будущего: отсутствие использования будущих значений KPI

---

## Датасеты
- Период: 2018–2024 (65 месяца на категорию)
- Частота: месячная
- Количество строк: ~2800
- Количество признаков: 12–20
Для проекта используются реальные внутренние данные компании из файла `Data Channels.xlsx`.

Датасет - по ссылке: _
[ссылка](https://disk.yandex.ru/i/gLTilFatrVPebg), _

**Основные поля:**

| Поле | Описание |
|------|----------|
| PER_SDESC | месяц и год периода |
| MT_Volume | объём продаж категории за месяц |
| NT_CWD | среднее количество недель продаж |
| NT_Avg Line | средняя линейная цена |
| NT_Price per kg | цена 1 кг товара |
| NT_Universe / MT_Universe | размер дистрибуции |
| Frequency | частота покупок |
| Penetration | доля домохозяйств, покупающих категорию |
| Spend per Trip | затраты покупателя за визит |
| Volume per Trip | количество товара за визит |

**Особенности данных:**

- Сильная сезонность
- Маркетинговые влияния (промо, изменения цены, дистрибуции)
- Агрегированная природа данных
- Корреляция признаков
- Пропуски и редкие скачки


## Моделирование

### Бейзлайн

В качестве простейших подходов для задачи прогнозирования месячных продаж будут использованы классические временные методы.
Они позволят сформировать нижнюю границу качества и оценить прирост метрик после применения нейросетей.


## Основная модель

Так как данные содержат множество факторов (цена, охват, пенетрация, средний чек, частота покупок), простые модели не способны уловить сложные нелинейные взаимосвязи. В проекте используется современная нейросетевая архитектура для временных рядов — **Temporal Fusion Transformer (TFT)**.

- **Ссылка на оригинальную статью:** [Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting](https://arxiv.org/abs/1912.09363)

### Почему TFT подходит под задачу

- Учитывает мультивариантные временные ряды, что важно при наличии большого числа KPI.
- Может обрабатывать:
  - статические признаки (категория, канал),
  - временные признаки (месяц, год),
  - неизвестные будущие признаки (например, планируемые цены, Universe),
  - известные будущие признаки (календарные фичи).
- Даёт интерпретируемость благодаря механизму внимания (**attention**): показывает важность цены, пенетрации, частоты, Universe и других факторов.
- Работает лучше LSTM на длинных горизонтах прогнозирования.

### Структура модели

- **LSTM Encoder–Decoder** — извлечение временных зависимостей
- **Self-Attention** — выделение значимых периодов
- **Variable Selection Network (VSN)** — автоматически определяет важность признаков
- **Gated Residual Network (GRN)** — стабилизирует обучение
- **Prediction Head** — генерация прогноза на H месяцев вперёд

### Обучение модели

- **Библиотеки:** PyTorch + PyTorch Lightning
- **Оптимизатор:** Adam (lr = 1e−3 … 1e−4)
- **Функция потерь:** MAPE / MAE / RMSE (тестируются несколько вариантов)
- **Регуляризация:** Dropout 0.1–0.25
- **Batch formation:** sliding-window (например, 36 → 1)
- **Валидация:** TimeSeriesSplit
- **Ранняя остановка:** по WAPE или sMAPE
- **Подбор гиперпараметров:** Optuna

Модель обучается на окнах длиной 24–36 месяцев и предсказывает горизонты от 1 до 3–6 месяцев вперёд.

### Внедрение

## Code Management и Reproducibility

Код проекта хранится в **Git** (GitHub). Используются:

- Ветвление Git (**feature-branches**)
- **pre-commit hooks** для контроля качества кода
- Версионирование модели и кода

Это обеспечивает воспроизводимость экспериментов и упрощает переносимость проекта.

---

## Data Storage и Управление данными

Данные хранятся в:

- S3-совместимом хранилище (например, **MinIO** или **Yandex Object Storage**)

Для удобства используется:

- **DVC (Data Version Control)** — управление версиями сырых и преобразованных данных
- **Parquet** — оптимизированный формат хранения


---


## Experiments Tracking

Для отслеживания экспериментов используется **MLflow Tracking**.

Отслеживаются:

- Гиперпараметры
- Метрики (**MAE, WAPE, RMSE**)
- Дата обучения
- Версия модели
- Структура данных
- Обучающие и валидационные выборки

Все модели регистрируются в **MLflow Model Registry**.


## Setup
Обобщённые шаги для проверки работы:

1. Клонируем репозиторий:

```bash
git clone <URL_репозитория>
cd <папка_репозитория>
poetry install
poetry shell
pre-commit install
pre-commit run -a


## Train
## Train Module

Модуль `training/train.py` отвечает за полное обучение модели TFT на временных рядах FMCG-продаж.

### Основные шаги

1. **Загрузка данных**
   - Данные скачиваются из DVC (локально или из S3/Yandex Object Storage)

2. **Предобработка**
   - Масштабирование числовых признаков и One-Hot кодирование категориальных
   - Сохранение предобработанных объектов в `artifacts/`

3. **Формирование датасетов**
   - Класс `FMCGForecastDataset` с скользящим окном
   - Train: до 2022, Validation: 2023

4. **Модель и обучение**
   - `TFTLightningModule` на PyTorch Lightning
   - Метрики: MAE, RMSE, sMAPE, WAPE
   - Callbacks: `ModelCheckpoint` и `EarlyStopping`
   - Логирование в MLflow (`MLFlowLogger`)

5. **Сохранение результатов**
   - Чекпоинты в `checkpoints/`
   - Предобработанные объекты: `artifacts/scaler.pkl`, `artifacts/ohe.pkl`
   - Метаданные меток: `data/labels_metainfo/id2labels_metainfo.json`

### Запуск

1. Запуск MLflow Server для логирования:

```bash
poetry run mlflow ui --port 8080

2. Отдельным окном

```bash
poetry run python -m fmcg_sales_forecasting.training.train

## Infer Module

Модуль `infer/fmcg_inference.py` отвечает за инференс (предсказания) на новых данных с использованием предобученной модели TFT.

### Основные шаги

1. **Загрузка данных**
   - Данные скачиваются из DVC (`cfg.infer.path_in_dvc`)

2. **Загрузка предобработчиков**
   - `scaler` и `One-Hot Encoder` загружаются из `artifacts/`

3. **Предобработка данных**
   - Масштабирование и кодирование с помощью `preprocess_fmcg`
   - Создаётся `FMCGForecastDataset` для тестовой выборки

4. **Загрузка модели**
   - Модель TFT загружается из чекпоинта (`cfg.infer.checkpoint_path`)
   - Включает вычисление метрик: MAE, RMSE, sMAPE, WAPE

5. **Предсказания и метрики**
   - Используется DataLoader для батчей
   - Предсказания и цели собираются в `all_preds` и `all_targets`
   - Рассчитываются метрики и логируются в MLflow

### Запуск

```bash
poetry run python -m fmcg_sales_forecasting.infer.fmcg_inference
